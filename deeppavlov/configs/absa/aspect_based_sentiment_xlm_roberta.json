{
  "dataset_reader": {
    "class_name": "semeval2015_absa_reader",
    "data_path": "semeval2015",
    "dataset_name": "semeval2015_absa_reader",
    "provide_pos": false
  },
  "dataset_iterator": {
    "class_name": "data_learning_iterator"
  },
  "chainer": {
    "in": [
      "x"
    ],
    "in_y": [
      "y"
    ],
    "pipe": [
      {
        "class_name": "torch_transformers_absa_preprocessor",
        "vocab_file": "{BASE_MODEL}",
        "in": [
          "x"
        ],
        "out": [
          "x_tokens",
          "x_subword_tokens",
          "x_subword_tok_ids",
          "startofword_markers",
          "attention_mask",
          "tokens_offsets"
        ]
      },
      {
        "id": "tag_vocab",
        "class_name": "simple_vocab",
        "unk_token": [
          "3"
        ],
        "save_path": "{MODEL_PATH}/tag.dict",
        "load_path": "{MODEL_PATH}/tag.dict",
        "fit_on": [
          "y"
        ],
        "in": [
          "y"
        ],
        "out": [
          "y_ind"
        ]
      },
      {
        "class_name": "torch_transformers_absa_tagger",
        "n_tags": "#tag_vocab.len",
        "pretrained_bert": "{BASE_MODEL}",
        "save_path": "{MODEL_PATH}",
        "in": [
          "x_subword_tok_ids",
          "attention_mask",
          "startofword_markers"
        ],
        "in_y": [
          "y_ind"
        ],
        "out": [
          "y_pred_ind"
        ]
      },
      {
        "ref": "tag_vocab",
        "in": [
          "y_pred_ind"
        ],
        "out": [
          "y_pred"
        ]
      }
    ],
    "out": [
      "x_tokens",
      "y_pred"
    ]
  },
  "train": {
    "epochs": 10,
    "batch_size": 32,
    "metrics": [
      {
        "name": "absa_accuracy",
        "inputs": [
          "y",
          "y_pred"
        ]
      }
    ],
    "validation_patience": 100,
    "val_every_n_batches": 20,
    "log_every_n_batches": 20,
    "show_examples": false,
    "pytest_max_batches": 2,
    "pytest_batch_size": 8,
    "evaluation_targets": [
      "valid",
      "test"
    ],
    "class_name": "torch_trainer"
  },
  "metadata": {
    "variables": {
      "BASE_MODEL": "Davlan/xlm-roberta-base-ner-hrl",
      "ROOT_PATH": "ABSA",
      "DOWNLOADS_PATH": "{ROOT_PATH}",
      "MODELS_PATH": "{ROOT_PATH}",
      "MODEL_PATH": "model_files"
    }
  }
}
